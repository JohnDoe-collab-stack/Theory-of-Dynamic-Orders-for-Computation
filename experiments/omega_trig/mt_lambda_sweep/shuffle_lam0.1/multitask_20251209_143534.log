14:35:34 | === Multi-Task Training (Î»_halt=0.1) ===
14:35:34 | Log: mt_lambda_sweep/shuffle_lam0.1\multitask_20251209_143534.log
14:35:34 | Config: MultiTaskConfig(epochs=60, lr=0.001, batch_size=64, seed=42, angle_embed_dim=16, index_embed_dim=8, hidden_dim=64, lambda_halt=0.1, n_halt_classes=4, shuffle_K=True, checkpoint_epochs=[0, 1, 5, 10, 20, 50], output_dir='mt_lambda_sweep/shuffle_lam0.1', t_first_K_path='checkpoints_trig/t_first_K.json')
14:35:34 | 
14:35:34 | Loading t_first^K from checkpoints_trig/t_first_K.json...
14:35:34 |   Loaded 2880 difficulty values
14:35:34 |   SHUFFLING t_first^K (random control)
14:35:34 | Generating dataset...
14:35:34 |   Train: 2015, halt dist: {3: 998, 1: 567, 0: 450}
14:35:34 | Model: 6,157 parameters
14:35:36 | Epoch   0 | Loss: inf (y:inf, h:inf) | Y: 0.486 | Halt: 0.162
14:35:37 | Epoch   1 | Loss: 0.7741 (y:0.6379, h:1.3623) | Y: 0.859 | Halt: 0.516
14:35:41 | Epoch   5 | Loss: 0.2294 (y:0.1247, h:1.0475) | Y: 0.970 | Halt: 0.519
14:35:45 | Epoch  10 | Loss: 0.1589 (y:0.0546, h:1.0432) | Y: 0.988 | Halt: 0.519
14:35:50 | Epoch  20 | Loss: 0.1353 (y:0.0315, h:1.0380) | Y: 0.993 | Halt: 0.519
14:36:08 | Epoch  50 | Loss: 0.1219 (y:0.0183, h:1.0366) | Y: 0.998 | Halt: 0.519
14:36:08 | 
Final Test: Y=0.995, Halt=0.501
14:36:08 | 
14:36:08 | === Multi-Task Training Complete ===
14:36:08 | Checkpoints saved to: mt_lambda_sweep/shuffle_lam0.1/
